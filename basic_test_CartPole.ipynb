{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Q_nn():\n",
    "    \n",
    "    def __init__(self, scope = 'estimator'):\n",
    "        self.scope = scope\n",
    "        with tf.variable_scope(scope):\n",
    "            self.__build_graph()\n",
    "            \n",
    "\n",
    "    def __build_graph(self):\n",
    "        # state matrix\n",
    "        self.X_states = tf.placeholder(shape = [None, 4], dtype = tf.float32)\n",
    "        \n",
    "        # target values (R+maxQ)\n",
    "        self.Q_targets = tf.placeholder(shape = [None], dtype = tf.float32)\n",
    "            \n",
    "        # action as an index\n",
    "        self.actions = tf.placeholder(shape = [None], dtype = tf.int32)\n",
    "        \n",
    "        self.batch_size = self.X_states.shape[0]\n",
    "        self.action_size = 2\n",
    "        self.action_one_hots = tf.one_hot(self.actions,self.action_size,axis = -1)\n",
    "        \n",
    "        self.W_fc1 = tf.Variable(tf.truncated_normal([4,32],0.1))\n",
    "        self.b_fc1 = tf.Variable(tf.constant(0.1,shape=[32]))\n",
    "        self.fc1 = tf.matmul(self.X_states,self.W_fc1) + self.b_fc1\n",
    "        \n",
    "        self.relu1 = tf.nn.relu(self.fc1)\n",
    "        \n",
    "        self.W_fc2 = tf.Variable(tf.truncated_normal([32,2],0.1))\n",
    "        self.b_fc2 = tf.Variable(tf.constant(0.1,shape=[2]))\n",
    "        \n",
    "        self.Q_est = tf.matmul(self.relu1,self.W_fc2) + self.b_fc2\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.action_Qs = tf.reduce_sum(tf.multiply(self.Q_est,self.action_one_hots),-1)\n",
    "               \n",
    "        self.loss = tf.losses.mean_squared_error(self.Q_targets, self.action_Qs)\n",
    "        \n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "\n",
    "    def predict(self, sess, state):\n",
    "        return sess.run(self.Q_est, { self.X_states: state })\n",
    "        \n",
    "        \n",
    "    def update(self, sess, states, actions, targets):\n",
    "        feed_dict = { self.X_states: states, self.Q_targets: targets, self.actions: actions}\n",
    "        _, loss = sess.run([self.train_op, self.loss], feed_dict)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "class NetworkCopier():\n",
    "    def __init__(self, estimator,target):\n",
    "        est_vars = [variable for variable in tf.trainable_variables() if variable.name.startswith(estimator.scope)]\n",
    "        est_vars = sorted(est_vars, key = lambda x: x.name)\n",
    "\n",
    "        tar_vars = [variable for variable in tf.trainable_variables() if variable.name.startswith(target.scope)]\n",
    "        tar_vars = sorted(tar_vars, key = lambda x: x.name)\n",
    "\n",
    "        self.update_ops = [tar_var.assign(est_var) for est_var,tar_var in zip(est_vars,tar_vars)]\n",
    "    \n",
    "    \n",
    "    def copy_and_freeze(self,sess): \n",
    "        sess.run(self.update_ops)\n",
    "        \n",
    "        \n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size = 10000):\n",
    "        self.buffer = []\n",
    "        self.max_size = max_size\n",
    "        \n",
    "        \n",
    "    def add_new(self, state, action, reward, next_state):\n",
    "        if len(self.buffer) >= self.max_size:\n",
    "            _ = self.buffer.pop()\n",
    "        entry = (state,action,reward,next_state)\n",
    "        self.buffer.append(entry)\n",
    "        \n",
    "        \n",
    "    def batch(self, n = 100):\n",
    "        if len(self.buffer) < n:\n",
    "            return self.buffer\n",
    "        else:\n",
    "            return random.sample(self.buffer, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-28 00:34:56,226] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Set\n"
     ]
    }
   ],
   "source": [
    "episodes = 10000\n",
    "explore_steps = 250 # how many episodes to do pure exploration\n",
    "iterations = 10 # per episode\n",
    "max_steps = 1000 # per episode\n",
    "batch_size = 100\n",
    "discount = 0.9\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "Q_estimator = Q_nn(scope = 'estimator')\n",
    "Q_target = Q_nn(scope = 'target')\n",
    "Freezer = NetworkCopier(Q_estimator,Q_target)\n",
    "Buffer = ReplayBuffer(2500)\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "env = gym.make('CartPole-v0')\n",
    "print('Graph Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, loss: 33.80260791778564, total steps = 18.0\n",
      "Episode 25, loss: 0.5409657686948777, total steps = 22.0\n",
      "Episode 50, loss: 0.34227833300828936, total steps = 16.0\n",
      "Episode 75, loss: 0.21838380992412568, total steps = 13.0\n",
      "Episode 100, loss: 0.16771242171525955, total steps = 20.0\n",
      "Episode 125, loss: 0.141452556848526, total steps = 22.0\n",
      "Episode 150, loss: 0.11481173038482666, total steps = 34.0\n",
      "Episode 175, loss: 0.12878579497337342, total steps = 12.0\n",
      "Episode 200, loss: 0.10050932168960572, total steps = 12.0\n",
      "Episode 225, loss: 0.10115797594189643, total steps = 27.0\n",
      "Episode 250, loss: 0.10691907331347465, total steps = 38.0\n",
      "Episode 275, loss: 0.09224972799420357, total steps = 14.0\n",
      "Episode 300, loss: 0.09253381937742233, total steps = 9.0\n",
      "Episode 325, loss: 0.08250379301607609, total steps = 10.0\n",
      "Episode 350, loss: 0.07631386779248714, total steps = 8.0\n",
      "Episode 375, loss: 0.07134317383170127, total steps = 9.0\n",
      "Episode 400, loss: 0.08036250546574593, total steps = 10.0\n",
      "Episode 425, loss: 0.07079937271773815, total steps = 10.0\n",
      "Episode 450, loss: 0.07746290899813175, total steps = 10.0\n",
      "Episode 475, loss: 0.07548493184149266, total steps = 10.0\n",
      "Episode 500, loss: 0.07008988671004772, total steps = 9.0\n",
      "Episode 525, loss: 0.07213058024644851, total steps = 8.0\n",
      "Episode 550, loss: 0.06788673661649228, total steps = 11.0\n",
      "Episode 575, loss: 0.06952329836785794, total steps = 13.0\n",
      "Episode 600, loss: 0.07625886462628842, total steps = 9.0\n",
      "Episode 625, loss: 0.07355513721704483, total steps = 11.0\n",
      "Episode 650, loss: 0.06698204874992371, total steps = 9.0\n",
      "Episode 675, loss: 0.07584820240736008, total steps = 10.0\n",
      "Episode 700, loss: 0.07561007998883724, total steps = 9.0\n",
      "Episode 725, loss: 0.0763666421175003, total steps = 9.0\n",
      "Episode 750, loss: 0.08043369017541409, total steps = 10.0\n",
      "Episode 775, loss: 0.07839184366166592, total steps = 10.0\n",
      "Episode 800, loss: 0.07729827277362347, total steps = 10.0\n",
      "Episode 825, loss: 0.08319260105490685, total steps = 9.0\n",
      "Episode 850, loss: 0.07743805199861527, total steps = 9.0\n",
      "Episode 875, loss: 0.08246631473302841, total steps = 9.0\n",
      "Episode 900, loss: 0.07473677657544613, total steps = 11.0\n",
      "Episode 925, loss: 0.07916508503258228, total steps = 10.0\n",
      "Episode 950, loss: 0.07431074418127537, total steps = 8.0\n",
      "Episode 975, loss: 0.07512593790888786, total steps = 10.0\n",
      "Episode 1000, loss: 0.07809364572167396, total steps = 9.0\n",
      "Episode 1025, loss: 0.08207890801131726, total steps = 10.0\n",
      "Episode 1050, loss: 0.08393106386065483, total steps = 8.0\n",
      "Episode 1075, loss: 0.08588236719369888, total steps = 10.0\n",
      "Episode 1100, loss: 0.08357360884547234, total steps = 12.0\n",
      "Episode 1125, loss: 0.08079559355974197, total steps = 10.0\n",
      "Episode 1150, loss: 0.08256326615810394, total steps = 10.0\n",
      "Episode 1175, loss: 0.08439054414629936, total steps = 11.0\n",
      "Episode 1200, loss: 0.08267395347356796, total steps = 12.0\n",
      "Episode 1225, loss: 0.0747949093580246, total steps = 14.0\n",
      "Episode 1250, loss: 0.080934789031744, total steps = 10.0\n",
      "Episode 1275, loss: 0.07094033174216748, total steps = 8.0\n",
      "Episode 1300, loss: 0.07505301609635354, total steps = 9.0\n",
      "Episode 1325, loss: 0.069504114985466, total steps = 9.0\n",
      "Episode 1350, loss: 0.07283672839403152, total steps = 8.0\n",
      "Episode 1375, loss: 0.07406303994357585, total steps = 9.0\n",
      "Episode 1400, loss: 0.06677230447530746, total steps = 12.0\n",
      "Episode 1425, loss: 0.07790576778352261, total steps = 9.0\n",
      "Episode 1450, loss: 0.07447161003947259, total steps = 10.0\n",
      "Episode 1475, loss: 0.07322275377810002, total steps = 10.0\n",
      "Episode 1500, loss: 0.07607077658176423, total steps = 11.0\n",
      "Episode 1525, loss: 0.06507222391664982, total steps = 10.0\n",
      "Episode 1550, loss: 0.0690259214490652, total steps = 9.0\n",
      "Episode 1575, loss: 0.07280504181981087, total steps = 10.0\n",
      "Episode 1600, loss: 0.07256692424416541, total steps = 10.0\n",
      "Episode 1625, loss: 0.06753707230091095, total steps = 11.0\n",
      "Episode 1650, loss: 0.06712270006537438, total steps = 12.0\n",
      "Episode 1675, loss: 0.07311068587005139, total steps = 9.0\n",
      "Episode 1700, loss: 0.06917429752647877, total steps = 9.0\n",
      "Episode 1725, loss: 0.064597562327981, total steps = 9.0\n",
      "Episode 1750, loss: 0.06555818319320679, total steps = 10.0\n",
      "Episode 1775, loss: 0.06623520143330097, total steps = 10.0\n",
      "Episode 1800, loss: 0.059530794620513916, total steps = 8.0\n",
      "Episode 1825, loss: 0.06372979022562504, total steps = 9.0\n",
      "Episode 1850, loss: 0.06422065123915673, total steps = 9.0\n",
      "Episode 1875, loss: 0.06105730123817921, total steps = 11.0\n",
      "Episode 1900, loss: 0.06331422068178653, total steps = 9.0\n",
      "Episode 1925, loss: 0.06215876154601574, total steps = 8.0\n",
      "Episode 1950, loss: 0.06442535445094108, total steps = 10.0\n",
      "Episode 1975, loss: 0.05973075293004513, total steps = 10.0\n",
      "Episode 2000, loss: 0.05878058224916458, total steps = 9.0\n",
      "Episode 2025, loss: 0.06092440076172352, total steps = 9.0\n",
      "Episode 2050, loss: 0.060884622111916545, total steps = 12.0\n",
      "Episode 2075, loss: 0.061882926151156425, total steps = 9.0\n",
      "Episode 2100, loss: 0.05875492691993713, total steps = 11.0\n",
      "Episode 2125, loss: 0.05694313906133175, total steps = 11.0\n",
      "Episode 2150, loss: 0.05854332819581032, total steps = 10.0\n",
      "Episode 2175, loss: 0.05497472621500492, total steps = 10.0\n",
      "Episode 2200, loss: 0.05945288278162479, total steps = 9.0\n",
      "Episode 2225, loss: 0.060646825656294825, total steps = 10.0\n",
      "Episode 2250, loss: 0.06019575037062168, total steps = 9.0\n",
      "Episode 2275, loss: 0.0552586916834116, total steps = 10.0\n",
      "Episode 2300, loss: 0.05742911733686924, total steps = 10.0\n",
      "Episode 2325, loss: 0.05706160627305508, total steps = 10.0\n",
      "Episode 2350, loss: 0.0571945920586586, total steps = 9.0\n",
      "Episode 2375, loss: 0.05597817003726959, total steps = 10.0\n",
      "Episode 2400, loss: 0.05634630024433136, total steps = 9.0\n",
      "Episode 2425, loss: 0.0565225463360548, total steps = 10.0\n",
      "Episode 2450, loss: 0.05060151591897011, total steps = 10.0\n",
      "Episode 2475, loss: 0.050304166972637177, total steps = 8.0\n",
      "Episode 2500, loss: 0.055407775193452836, total steps = 10.0\n",
      "Episode 2525, loss: 0.049192788824439046, total steps = 9.0\n",
      "Episode 2550, loss: 0.04924915507435799, total steps = 9.0\n",
      "Episode 2575, loss: 0.05008156485855579, total steps = 8.0\n",
      "Episode 2600, loss: 0.05113806501030922, total steps = 9.0\n",
      "Episode 2625, loss: 0.05315564684569836, total steps = 9.0\n",
      "Episode 2650, loss: 0.04881923161447048, total steps = 11.0\n",
      "Episode 2675, loss: 0.04665087442845106, total steps = 11.0\n",
      "Episode 2700, loss: 0.04772857166826725, total steps = 10.0\n",
      "Episode 2725, loss: 0.05289191529154778, total steps = 9.0\n",
      "Episode 2750, loss: 0.048967666923999786, total steps = 9.0\n",
      "Episode 2775, loss: 0.04324535895138979, total steps = 9.0\n",
      "Episode 2800, loss: 0.046736479923129085, total steps = 12.0\n",
      "Episode 2825, loss: 0.049173635244369504, total steps = 10.0\n",
      "Episode 2850, loss: 0.041049901582300666, total steps = 10.0\n",
      "Episode 2875, loss: 0.0408156767487526, total steps = 9.0\n",
      "Episode 2900, loss: 0.04168795924633741, total steps = 9.0\n",
      "Episode 2925, loss: 0.04036571830511093, total steps = 9.0\n",
      "Episode 2950, loss: 0.04246118701994419, total steps = 9.0\n",
      "Episode 2975, loss: 0.04064755868166685, total steps = 12.0\n",
      "Episode 3000, loss: 0.04098343998193741, total steps = 9.0\n",
      "Episode 3025, loss: 0.03763970527797937, total steps = 11.0\n",
      "Episode 3050, loss: 0.03866694588214159, total steps = 10.0\n",
      "Episode 3075, loss: 0.036321651004254815, total steps = 9.0\n",
      "Episode 3100, loss: 0.0333932101726532, total steps = 10.0\n",
      "Episode 3125, loss: 0.0328129205852747, total steps = 10.0\n",
      "Episode 3150, loss: 0.0345992473885417, total steps = 10.0\n",
      "Episode 3175, loss: 0.034358445182442666, total steps = 10.0\n",
      "Episode 3200, loss: 0.03623256180435419, total steps = 10.0\n",
      "Episode 3225, loss: 0.030446262285113334, total steps = 9.0\n",
      "Episode 3250, loss: 0.03272296730428934, total steps = 10.0\n",
      "Episode 3275, loss: 0.03330889008939266, total steps = 12.0\n",
      "Episode 3300, loss: 0.03675766903907061, total steps = 9.0\n",
      "Episode 3325, loss: 0.03497685827314854, total steps = 9.0\n",
      "Episode 3350, loss: 0.03505728915333748, total steps = 10.0\n",
      "Episode 3375, loss: 0.03211510721594095, total steps = 8.0\n",
      "Episode 3400, loss: 0.03239024449139834, total steps = 10.0\n",
      "Episode 3425, loss: 0.030974645726382734, total steps = 9.0\n",
      "Episode 3450, loss: 0.03331079464405775, total steps = 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3475, loss: 0.030641797184944152, total steps = 10.0\n",
      "Episode 3500, loss: 0.02973885778337717, total steps = 10.0\n",
      "Episode 3525, loss: 0.033653955720365045, total steps = 9.0\n",
      "Episode 3550, loss: 0.029173130728304388, total steps = 8.0\n",
      "Episode 3575, loss: 0.029712295904755593, total steps = 9.0\n",
      "Episode 3600, loss: 0.02933363225311041, total steps = 10.0\n",
      "Episode 3625, loss: 0.0288596298545599, total steps = 11.0\n",
      "Episode 3650, loss: 0.02986489497125149, total steps = 9.0\n",
      "Episode 3675, loss: 0.028802960738539697, total steps = 10.0\n",
      "Episode 3700, loss: 0.027466177381575106, total steps = 9.0\n",
      "Episode 3725, loss: 0.0286336675286293, total steps = 9.0\n",
      "Episode 3750, loss: 0.02598653994500637, total steps = 8.0\n",
      "Episode 3775, loss: 0.028859657421708106, total steps = 12.0\n",
      "Episode 3800, loss: 0.0259414903819561, total steps = 9.0\n",
      "Episode 3825, loss: 0.025734616629779338, total steps = 9.0\n",
      "Episode 3850, loss: 0.029600246250629424, total steps = 10.0\n",
      "Episode 3875, loss: 0.028010027296841145, total steps = 10.0\n",
      "Episode 3900, loss: 0.02521199584007263, total steps = 9.0\n",
      "Episode 3925, loss: 0.026532713696360587, total steps = 10.0\n",
      "Episode 3950, loss: 0.029245713353157045, total steps = 10.0\n",
      "Episode 3975, loss: 0.02565509043633938, total steps = 9.0\n",
      "Episode 4000, loss: 0.024444515444338323, total steps = 8.0\n",
      "Episode 4025, loss: 0.024512628093361855, total steps = 9.0\n",
      "Episode 4050, loss: 0.026141237840056418, total steps = 10.0\n",
      "Episode 4075, loss: 0.027104074135422707, total steps = 8.0\n",
      "Episode 4100, loss: 0.021486598998308182, total steps = 9.0\n",
      "Episode 4125, loss: 0.02409560177475214, total steps = 10.0\n",
      "Episode 4150, loss: 0.02572638913989067, total steps = 14.0\n",
      "Episode 4175, loss: 0.022910888493061065, total steps = 10.0\n",
      "Episode 4200, loss: 0.02341714147478342, total steps = 10.0\n",
      "Episode 4225, loss: 0.026148374378681182, total steps = 14.0\n",
      "Episode 4250, loss: 0.02807905189692974, total steps = 10.0\n",
      "Episode 4275, loss: 0.023249148204922677, total steps = 8.0\n",
      "Episode 4300, loss: 0.025434868596494197, total steps = 10.0\n",
      "Episode 4325, loss: 0.02192640248686075, total steps = 12.0\n",
      "Episode 4350, loss: 0.021890875510871412, total steps = 10.0\n",
      "Episode 4375, loss: 0.023767742700874804, total steps = 10.0\n",
      "Episode 4400, loss: 0.022966158390045167, total steps = 9.0\n",
      "Episode 4425, loss: 0.02173042818903923, total steps = 9.0\n",
      "Episode 4450, loss: 0.023614856228232384, total steps = 9.0\n",
      "Episode 4475, loss: 0.021856059040874242, total steps = 12.0\n",
      "Episode 4500, loss: 0.023275119811296464, total steps = 9.0\n",
      "Episode 4525, loss: 0.022491718363016843, total steps = 8.0\n",
      "Episode 4550, loss: 0.022649072483181952, total steps = 14.0\n",
      "Episode 4575, loss: 0.022317325696349144, total steps = 9.0\n",
      "Episode 4600, loss: 0.02097914684563875, total steps = 9.0\n",
      "Episode 4625, loss: 0.02208537608385086, total steps = 11.0\n",
      "Episode 4650, loss: 0.023037453554570674, total steps = 8.0\n",
      "Episode 4675, loss: 0.019256891589611767, total steps = 11.0\n",
      "Episode 4700, loss: 0.022274547163397072, total steps = 10.0\n",
      "Episode 4725, loss: 0.020580402947962283, total steps = 10.0\n",
      "Episode 4750, loss: 0.023149524442851545, total steps = 10.0\n",
      "Episode 4775, loss: 0.02366431653499603, total steps = 9.0\n",
      "Episode 4800, loss: 0.01973795797675848, total steps = 12.0\n",
      "Episode 4825, loss: 0.02127040345221758, total steps = 11.0\n",
      "Episode 4850, loss: 0.020010394044220448, total steps = 9.0\n",
      "Episode 4875, loss: 0.020645303279161455, total steps = 8.0\n",
      "Episode 4900, loss: 0.019946115650236608, total steps = 8.0\n",
      "Episode 4925, loss: 0.02245082799345255, total steps = 11.0\n",
      "Episode 4950, loss: 0.02015721909701824, total steps = 9.0\n",
      "Episode 4975, loss: 0.01959094572812319, total steps = 9.0\n",
      "Episode 5000, loss: 0.019178240932524203, total steps = 9.0\n",
      "Episode 5025, loss: 0.018379891663789748, total steps = 11.0\n",
      "Episode 5050, loss: 0.01991540901362896, total steps = 9.0\n",
      "Episode 5075, loss: 0.02043862473219633, total steps = 11.0\n",
      "Episode 5100, loss: 0.021197893004864455, total steps = 10.0\n",
      "Episode 5125, loss: 0.019656220078468324, total steps = 10.0\n",
      "Episode 5150, loss: 0.017174879275262355, total steps = 10.0\n",
      "Episode 5175, loss: 0.0195109598338604, total steps = 10.0\n",
      "Episode 5200, loss: 0.019270924106240272, total steps = 9.0\n",
      "Episode 5225, loss: 0.018851957377046348, total steps = 10.0\n",
      "Episode 5250, loss: 0.017702555377036334, total steps = 10.0\n",
      "Episode 5275, loss: 0.019345540925860404, total steps = 10.0\n",
      "Episode 5300, loss: 0.018180958088487388, total steps = 8.0\n",
      "Episode 5325, loss: 0.016937421541661023, total steps = 11.0\n",
      "Episode 5350, loss: 0.019735228829085828, total steps = 8.0\n",
      "Episode 5375, loss: 0.017887616995722055, total steps = 9.0\n",
      "Episode 5400, loss: 0.01746574863791466, total steps = 10.0\n",
      "Episode 5425, loss: 0.018333267606794833, total steps = 10.0\n",
      "Episode 5450, loss: 0.017246846854686738, total steps = 9.0\n",
      "Episode 5475, loss: 0.016849861666560172, total steps = 10.0\n",
      "Episode 5500, loss: 0.018052522093057632, total steps = 9.0\n",
      "Episode 5525, loss: 0.017076915595680475, total steps = 11.0\n",
      "Episode 5550, loss: 0.019208382349461317, total steps = 9.0\n",
      "Episode 5575, loss: 0.018442949559539557, total steps = 9.0\n",
      "Episode 5600, loss: 0.017817616742104293, total steps = 10.0\n",
      "Episode 5625, loss: 0.0165550590492785, total steps = 9.0\n",
      "Episode 5650, loss: 0.019066244922578336, total steps = 11.0\n",
      "Episode 5675, loss: 0.017013260535895823, total steps = 10.0\n",
      "Episode 5700, loss: 0.0159381365403533, total steps = 10.0\n",
      "Episode 5725, loss: 0.016671000886708497, total steps = 14.0\n",
      "Episode 5750, loss: 0.019435331132262944, total steps = 11.0\n",
      "Episode 5775, loss: 0.015419882349669933, total steps = 10.0\n",
      "Episode 5800, loss: 0.015201704390347005, total steps = 10.0\n",
      "Episode 5825, loss: 0.014012884628027678, total steps = 10.0\n",
      "Episode 5850, loss: 0.018275430612266063, total steps = 10.0\n",
      "Episode 5875, loss: 0.016534399800002576, total steps = 10.0\n",
      "Episode 5900, loss: 0.01551234070211649, total steps = 14.0\n",
      "Episode 5925, loss: 0.016269204765558244, total steps = 10.0\n",
      "Episode 5950, loss: 0.01615155106410384, total steps = 9.0\n",
      "Episode 5975, loss: 0.014459980744868517, total steps = 10.0\n",
      "Episode 6000, loss: 0.01628731321543455, total steps = 9.0\n",
      "Episode 6025, loss: 0.01356284311041236, total steps = 9.0\n",
      "Episode 6050, loss: 0.015703368093818428, total steps = 12.0\n",
      "Episode 6075, loss: 0.01674809055402875, total steps = 8.0\n",
      "Episode 6100, loss: 0.015843513421714306, total steps = 9.0\n",
      "Episode 6125, loss: 0.015821887739002706, total steps = 10.0\n",
      "Episode 6150, loss: 0.015443424042314292, total steps = 9.0\n",
      "Episode 6175, loss: 0.014460403658449649, total steps = 12.0\n",
      "Episode 6200, loss: 0.01494688494130969, total steps = 11.0\n",
      "Episode 6225, loss: 0.014862467907369137, total steps = 10.0\n",
      "Episode 6250, loss: 0.012687345687299966, total steps = 9.0\n",
      "Episode 6275, loss: 0.01409771041944623, total steps = 10.0\n",
      "Episode 6300, loss: 0.014190402626991273, total steps = 11.0\n",
      "Episode 6325, loss: 0.013115333020687103, total steps = 10.0\n",
      "Episode 6350, loss: 0.012826150190085173, total steps = 11.0\n",
      "Episode 6375, loss: 0.013849946018308402, total steps = 11.0\n",
      "Episode 6400, loss: 0.014032362215220927, total steps = 9.0\n",
      "Episode 6425, loss: 0.014908332005143165, total steps = 13.0\n",
      "Episode 6450, loss: 0.012931849900633096, total steps = 12.0\n",
      "Episode 6475, loss: 0.01419009855017066, total steps = 11.0\n",
      "Episode 6500, loss: 0.013056785706430674, total steps = 9.0\n",
      "Episode 6525, loss: 0.012027382850646973, total steps = 9.0\n",
      "Episode 6550, loss: 0.013548214361071587, total steps = 14.0\n",
      "Episode 6575, loss: 0.013800908252596856, total steps = 10.0\n",
      "Episode 6600, loss: 0.0126990906894207, total steps = 9.0\n",
      "Episode 6625, loss: 0.012163664773106575, total steps = 9.0\n",
      "Episode 6650, loss: 0.011801210045814515, total steps = 9.0\n",
      "Episode 6675, loss: 0.01313705900683999, total steps = 10.0\n",
      "Episode 6700, loss: 0.013407256081700325, total steps = 10.0\n",
      "Episode 6725, loss: 0.011916073318570853, total steps = 11.0\n",
      "Episode 6750, loss: 0.011756189353764056, total steps = 9.0\n",
      "Episode 6775, loss: 0.012127905152738094, total steps = 10.0\n",
      "Episode 6800, loss: 0.010740595869719982, total steps = 11.0\n",
      "Episode 6825, loss: 0.01477849492803216, total steps = 9.0\n",
      "Episode 6850, loss: 0.012063328083604575, total steps = 8.0\n",
      "Episode 6875, loss: 0.011671477276831866, total steps = 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6900, loss: 0.011798636056482792, total steps = 9.0\n",
      "Episode 6925, loss: 0.01101508061401546, total steps = 11.0\n",
      "Episode 6950, loss: 0.011285526398569345, total steps = 10.0\n",
      "Episode 6975, loss: 0.011519200354814529, total steps = 8.0\n",
      "Episode 7000, loss: 0.010351148946210743, total steps = 11.0\n",
      "Episode 7025, loss: 0.009652772545814514, total steps = 11.0\n",
      "Episode 7050, loss: 0.010334680788218975, total steps = 10.0\n",
      "Episode 7075, loss: 0.009628517972305416, total steps = 9.0\n",
      "Episode 7100, loss: 0.010258476622402668, total steps = 9.0\n",
      "Episode 7125, loss: 0.012495662551373243, total steps = 9.0\n",
      "Episode 7150, loss: 0.011182739911600948, total steps = 11.0\n",
      "Episode 7175, loss: 0.010953758843243122, total steps = 9.0\n",
      "Episode 7200, loss: 0.009741020668298007, total steps = 10.0\n",
      "Episode 7225, loss: 0.01278283940628171, total steps = 10.0\n",
      "Episode 7250, loss: 0.009994249511510133, total steps = 10.0\n",
      "Episode 7275, loss: 0.00949524063616991, total steps = 9.0\n",
      "Episode 7300, loss: 0.0098013109061867, total steps = 9.0\n",
      "Episode 7325, loss: 0.00966630638577044, total steps = 9.0\n",
      "Episode 7350, loss: 0.010261643212288618, total steps = 10.0\n",
      "Episode 7375, loss: 0.009042166266590356, total steps = 10.0\n",
      "Episode 7400, loss: 0.010356861399486661, total steps = 9.0\n",
      "Episode 7425, loss: 0.010542029328644276, total steps = 10.0\n",
      "Episode 7450, loss: 0.009974466310814023, total steps = 11.0\n",
      "Episode 7475, loss: 0.009474158426746726, total steps = 9.0\n",
      "Episode 7500, loss: 0.01035958039574325, total steps = 9.0\n",
      "Episode 7525, loss: 0.008653341606259347, total steps = 12.0\n",
      "Episode 7550, loss: 0.009667447675019503, total steps = 8.0\n",
      "Episode 7575, loss: 0.008082109550014139, total steps = 10.0\n",
      "Episode 7600, loss: 0.009399644564837217, total steps = 9.0\n",
      "Episode 7625, loss: 0.010540581727400421, total steps = 8.0\n",
      "Episode 7650, loss: 0.010150347091257571, total steps = 10.0\n",
      "Episode 7675, loss: 0.009948818758130074, total steps = 9.0\n",
      "Episode 7700, loss: 0.009520958829671144, total steps = 10.0\n",
      "Episode 7725, loss: 0.00839769202284515, total steps = 11.0\n",
      "Episode 7750, loss: 0.008863858412951231, total steps = 10.0\n",
      "Episode 7775, loss: 0.009919276926666498, total steps = 9.0\n",
      "Episode 7800, loss: 0.00960448463447392, total steps = 10.0\n",
      "Episode 7825, loss: 0.00845848717726767, total steps = 9.0\n",
      "Episode 7850, loss: 0.009521517436951399, total steps = 9.0\n",
      "Episode 7875, loss: 0.010752524714916945, total steps = 9.0\n",
      "Episode 7900, loss: 0.009438440576195717, total steps = 9.0\n",
      "Episode 7925, loss: 0.010770411044359208, total steps = 11.0\n",
      "Episode 7950, loss: 0.009387946501374245, total steps = 11.0\n",
      "Episode 7975, loss: 0.008763377321884036, total steps = 9.0\n",
      "Episode 8000, loss: 0.009585208864882589, total steps = 10.0\n",
      "Episode 8025, loss: 0.009734617033973336, total steps = 10.0\n",
      "Episode 8050, loss: 0.00965604167431593, total steps = 11.0\n",
      "Episode 8075, loss: 0.00898633198812604, total steps = 9.0\n",
      "Episode 8100, loss: 0.008427244611084461, total steps = 9.0\n",
      "Episode 8125, loss: 0.008321410370990634, total steps = 11.0\n",
      "Episode 8150, loss: 0.00999188655987382, total steps = 10.0\n",
      "Episode 8175, loss: 0.008588953735306859, total steps = 10.0\n",
      "Episode 8200, loss: 0.00884680966846645, total steps = 10.0\n",
      "Episode 8225, loss: 0.008231080090627074, total steps = 10.0\n",
      "Episode 8250, loss: 0.008903729822486639, total steps = 10.0\n",
      "Episode 8275, loss: 0.008326114481315016, total steps = 10.0\n",
      "Episode 8300, loss: 0.00838257814757526, total steps = 9.0\n",
      "Episode 8325, loss: 0.009838640596717596, total steps = 10.0\n",
      "Episode 8350, loss: 0.009338213922455907, total steps = 8.0\n",
      "Episode 8375, loss: 0.008573100622743367, total steps = 11.0\n",
      "Episode 8400, loss: 0.008761968184262513, total steps = 11.0\n",
      "Episode 8425, loss: 0.009623682638630272, total steps = 10.0\n",
      "Episode 8450, loss: 0.009300983138382434, total steps = 10.0\n",
      "Episode 8475, loss: 0.007244250690564513, total steps = 9.0\n",
      "Episode 8500, loss: 0.00908359126187861, total steps = 10.0\n",
      "Episode 8525, loss: 0.008641350967809557, total steps = 10.0\n",
      "Episode 8550, loss: 0.008672596514225006, total steps = 8.0\n",
      "Episode 8575, loss: 0.008528621681034566, total steps = 9.0\n",
      "Episode 8600, loss: 0.008795465994626283, total steps = 8.0\n",
      "Episode 8625, loss: 0.009222423890605569, total steps = 15.0\n",
      "Episode 8650, loss: 0.0088468873873353, total steps = 8.0\n",
      "Episode 8675, loss: 0.00936600831337273, total steps = 10.0\n",
      "Episode 8700, loss: 0.009343260759487748, total steps = 10.0\n",
      "Episode 8725, loss: 0.007923908811062575, total steps = 8.0\n",
      "Episode 8750, loss: 0.008530390542000532, total steps = 10.0\n",
      "Episode 8775, loss: 0.008564669452607632, total steps = 10.0\n",
      "Episode 8800, loss: 0.00820196671411395, total steps = 11.0\n",
      "Episode 8825, loss: 0.008958714408800006, total steps = 9.0\n",
      "Episode 8850, loss: 0.008523776661604643, total steps = 9.0\n",
      "Episode 8875, loss: 0.008358458103612066, total steps = 10.0\n",
      "Episode 8900, loss: 0.007529962295666337, total steps = 10.0\n",
      "Episode 8925, loss: 0.007685086689889431, total steps = 12.0\n",
      "Episode 8950, loss: 0.009452345361933113, total steps = 9.0\n",
      "Episode 8975, loss: 0.008711592806503177, total steps = 9.0\n",
      "Episode 9000, loss: 0.008899056492373348, total steps = 10.0\n",
      "Episode 9025, loss: 0.00782363531179726, total steps = 9.0\n",
      "Episode 9050, loss: 0.008139104582369328, total steps = 9.0\n",
      "Episode 9075, loss: 0.008124457253143192, total steps = 10.0\n",
      "Episode 9100, loss: 0.008209297759458422, total steps = 12.0\n",
      "Episode 9125, loss: 0.008399829315021635, total steps = 11.0\n",
      "Episode 9150, loss: 0.00797558561898768, total steps = 9.0\n",
      "Episode 9175, loss: 0.007340544788166881, total steps = 10.0\n",
      "Episode 9200, loss: 0.007326096901670099, total steps = 10.0\n",
      "Episode 9225, loss: 0.007315948745235801, total steps = 10.0\n",
      "Episode 9250, loss: 0.007754263607785106, total steps = 8.0\n",
      "Episode 9275, loss: 0.008514522574841976, total steps = 9.0\n",
      "Episode 9300, loss: 0.008374226186424494, total steps = 8.0\n",
      "Episode 9325, loss: 0.007792871817946434, total steps = 9.0\n",
      "Episode 9350, loss: 0.007253634557127952, total steps = 13.0\n",
      "Episode 9375, loss: 0.00825373693369329, total steps = 12.0\n",
      "Episode 9400, loss: 0.007821427704766393, total steps = 8.0\n",
      "Episode 9425, loss: 0.007489431509748101, total steps = 8.0\n",
      "Episode 9450, loss: 0.006447397219017148, total steps = 11.0\n",
      "Episode 9475, loss: 0.007790792128071189, total steps = 9.0\n",
      "Episode 9500, loss: 0.008358203480020166, total steps = 9.0\n",
      "Episode 9525, loss: 0.007604562444612384, total steps = 12.0\n",
      "Episode 9550, loss: 0.006708405865356326, total steps = 10.0\n",
      "Episode 9575, loss: 0.007336787367239595, total steps = 8.0\n",
      "Episode 9600, loss: 0.007158463960513473, total steps = 9.0\n",
      "Episode 9625, loss: 0.007232876727357507, total steps = 12.0\n",
      "Episode 9650, loss: 0.0077383850235491995, total steps = 11.0\n",
      "Episode 9675, loss: 0.00791550031863153, total steps = 8.0\n",
      "Episode 9700, loss: 0.007731671258807182, total steps = 11.0\n",
      "Episode 9725, loss: 0.007733480259776116, total steps = 10.0\n",
      "Episode 9750, loss: 0.007564896997064352, total steps = 8.0\n",
      "Episode 9775, loss: 0.007338341139256954, total steps = 9.0\n",
      "Episode 9800, loss: 0.008413911331444979, total steps = 9.0\n",
      "Episode 9825, loss: 0.0073439428117126225, total steps = 10.0\n",
      "Episode 9850, loss: 0.007180014671757817, total steps = 8.0\n",
      "Episode 9875, loss: 0.0071677958592772486, total steps = 9.0\n",
      "Episode 9900, loss: 0.0072909561451524494, total steps = 10.0\n",
      "Episode 9925, loss: 0.007372946990653872, total steps = 10.0\n",
      "Episode 9950, loss: 0.006826752470806241, total steps = 10.0\n",
      "Episode 9975, loss: 0.007906164787709714, total steps = 10.0\n",
      "Wall time: 3h 26min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for e in range(episodes):\n",
    "    cumulative_loss = 0\n",
    "    if e < explore_steps: # pure exploration\n",
    "        epsilon = 1\n",
    "    else: # epsilon-greedy exploration/exploitation\n",
    "        epsilon = max(np.exp((e-explore_steps)/-50),0.1)\n",
    "    observation = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        curr_state = observation\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            curr_state_reshape = np.reshape(curr_state,(1,4))\n",
    "            q_est = Q_estimator.predict(sess,curr_state_reshape)\n",
    "            action = np.argmax(q_est)\n",
    "        \n",
    "        observation, reward, done, info = env.step(action)\n",
    "        next_state = observation\n",
    "        Buffer.add_new(curr_state, action, reward, next_state)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    for i in range(iterations):\n",
    "        states, actions, rewards, next_states = zip(*Buffer.batch(batch_size))\n",
    "        targets = []\n",
    "        for reward, next_state in zip(rewards,next_states):\n",
    "            next_state_reshape = np.reshape(next_state, (1,4))\n",
    "            q_max = np.max(Q_target.predict(sess,next_state_reshape))\n",
    "            target = reward + discount*q_max\n",
    "            targets.append(target)\n",
    "        state_array = np.stack(states,axis=0)\n",
    "        action_array = np.array(actions)\n",
    "        target_array = np.array(targets)\n",
    "        loss = Q_estimator.update(sess, state_array,action_array,target_array)\n",
    "        cumulative_loss += loss\n",
    "    if e%25 == 0:\n",
    "        Freezer.copy_and_freeze(sess)\n",
    "        print('Episode {}, loss: {}, total steps = {}'.format(e,cumulative_loss/iterations,total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luckiest of 100 random agents survives 83 time steps\n",
      "  Average random agent survived 22.56 time steps\n",
      "Best learned agent survives 11 time steps\n",
      "  Average learned agent survives 9.45 time steps\n",
      "Wall time: 977 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random_results = []\n",
    "agent_results = []\n",
    "for t in range(100):\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    total_steps = 0\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_steps += 1\n",
    "    random_results.append(total_steps)    \n",
    "\n",
    "for t in range(100):\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    total_steps = 0\n",
    "    while not done:\n",
    "        state_reshape = np.reshape(observation,(1,4))\n",
    "        q_est = Q_estimator.predict(sess,state_reshape)\n",
    "        action = np.argmax(q_est)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_steps += 1\n",
    "    agent_results.append(total_steps)\n",
    "print('Luckiest of 100 random agents survives {} time steps'.format(max(random_results)))\n",
    "print('  Average random agent survived {} time steps'.format(np.mean(random_results)))\n",
    "print('Best learned agent survives {} time steps'.format(max(agent_results)))\n",
    "print('  Average learned agent survives {} time steps'.format(np.mean(agent_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (airl)",
   "language": "python",
   "name": "airl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
